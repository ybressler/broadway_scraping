{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:3.0em\">\n",
    "    Wikipedia Scrape – Tony Nominees\n",
    "    <br>\n",
    "</span> \n",
    "\n",
    "<i> Some neat smooth functions for grabbing data from Wikipedia. There are some inadequacies, skip down to section 6 to read what they are.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import Functions and Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Prereqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T01:05:07.415736Z",
     "start_time": "2019-01-24T01:05:01.949143Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /Users/yaakov/anaconda3/lib/python3.6/site-packages (4.2.1)\n",
      "Requirement already satisfied: setuptools in /Users/yaakov/anaconda3/lib/python3.6/site-packages (39.1.0)\n",
      "Requirement already satisfied: requests in /Users/yaakov/anaconda3/lib/python3.6/site-packages (2.18.4)\n",
      "Collecting bs4\n",
      "  Downloading https://files.pythonhosted.org/packages/10/ed/7e8b97591f6f456174139ec089c769f89a94a1a4025fe967691de971f314/bs4-0.0.1.tar.gz\n",
      "Requirement already satisfied: pandas in /Users/yaakov/anaconda3/lib/python3.6/site-packages (0.23.4)\n",
      "Requirement already satisfied: numpy in /Users/yaakov/anaconda3/lib/python3.6/site-packages (1.14.3)\n",
      "Requirement already satisfied: IPython in /Users/yaakov/anaconda3/lib/python3.6/site-packages (6.4.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from requests) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from requests) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from requests) (2018.11.29)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from bs4) (4.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from pandas) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from pandas) (2018.4)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from IPython) (4.5.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from IPython) (4.3.2)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from IPython) (1.0.15)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from IPython) (0.8.1)\n",
      "Requirement already satisfied: pygments in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from IPython) (2.2.0)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from IPython) (0.1.0)\n",
      "Requirement already satisfied: decorator in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from IPython) (4.3.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from IPython) (0.12.0)\n",
      "Requirement already satisfied: pickleshare in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from IPython) (0.7.4)\n",
      "Requirement already satisfied: backcall in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from IPython) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.10.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->IPython) (0.5.2)\n",
      "Requirement already satisfied: ipython_genutils in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from traitlets>=4.2->IPython) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.15->IPython) (0.1.7)\n",
      "Requirement already satisfied: parso>=0.2.0 in /Users/yaakov/anaconda3/lib/python3.6/site-packages (from jedi>=0.10->IPython) (0.2.0)\n",
      "Building wheels for collected packages: bs4\n",
      "  Running setup.py bdist_wheel for bs4 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/yaakov/Library/Caches/pip/wheels/a0/b0/b2/4f80b9456b87abedbc0bf2d52235414c3467d8889be38dd472\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install lxml setuptools requests bs4 pandas numpy IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T00:58:32.617024Z",
     "start_time": "2019-01-24T00:58:32.608159Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from IPython.display import display_html\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Function to get tables from url\n",
    "\n",
    "<pre>\n",
    "get_tables_from_url(url)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T00:03:57.055628Z",
     "start_time": "2019-01-24T00:03:57.050110Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_tables_from_url(url):\n",
    "    \"\"\"\n",
    "    Gets a list of tables from an input url.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Request the document\n",
    "    r = requests.get(url)\n",
    "    html_doc = r.text\n",
    "    soup = BeautifulSoup(html_doc,'lxml')\n",
    "    \n",
    "    table_classes = {\"class\": [\"wikitable\"]}\n",
    "    tables = soup.findAll(\"table\", table_classes)\n",
    "    \n",
    "    return tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T10:21:35.061745Z",
     "start_time": "2019-01-23T10:21:35.056236Z"
    },
    "hidden": true
   },
   "source": [
    "## Function to get df from tables\n",
    "<pre>\n",
    "get_df_from_table(table_in)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T01:02:29.261311Z",
     "start_time": "2019-01-24T01:02:29.248001Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_df_from_table(table_in):\n",
    "    \"\"\"\n",
    "    returns a structured table for a beautiful soup table\n",
    "    \"\"\"\n",
    "    \n",
    "    ### SET UP REGEX\n",
    "    \n",
    "    re_1 = \"^\\d{4}\"\n",
    "    re_2 = \"\\d{1,2}(th|rd|st|nd) Tony Awards\"\n",
    "\n",
    "\n",
    "    # JUMP INTO IT!\n",
    "    parsed_table_data=[]\n",
    "    rows = table_in.findAll('tr')\n",
    "    \n",
    "    row_1 = rows[0]\n",
    "    children = row_1.findChildren(recursive=False)\n",
    "    r_n = len(children)\n",
    "\n",
    "    parsed_table_data = []\n",
    "    for row in rows:\n",
    "        children = row.findChildren(recursive=False)\n",
    "\n",
    "        row_text = []\n",
    "        cell_counter = 0\n",
    "        link = np.NAN\n",
    "        for child in children:\n",
    "            \n",
    "\n",
    "            clean_text = child.text\n",
    "\n",
    "            # We can sort each row as follows:\n",
    "            if re.findall(re_2,clean_text):\n",
    "                string  = clean_text\n",
    "                \n",
    "                # get the year\n",
    "                yr = re.match(re_1,string).group()\n",
    "                # split the string\n",
    "                string_2 = string.split(yr)[1]\n",
    "                # get the tony year\n",
    "                t_yr = re.match(re_2,string_2).group()\n",
    "                \n",
    "   \n",
    "\n",
    "                # Send the cleaned text back to the loop\n",
    "                clean_text = yr +' | ' + t_yr\n",
    "                row_text.append(clean_text)\n",
    "                \n",
    "                continue\n",
    "\n",
    "            #############################\n",
    "            # Get the url of the show of the row\n",
    "            \n",
    "            if cell_counter ==0:\n",
    "                # Only iterate the first cell\n",
    "                anchor = child.findAll('a')\n",
    "                for x in anchor:\n",
    "                    link = 'https://en.wikipedia.org' + x.get('href')\n",
    "                \n",
    "            #This is to discard reference/citation links\n",
    "            clean_text = clean_text.split('&#91;')[0]\n",
    "            #This is to clean the header row of the sort icons\n",
    "            clean_text = clean_text.split('&#160;')[-1]\n",
    "            # This discards demarcation of winner of pulitzer prize\n",
    "            clean_text = clean_text.replace('†','')\n",
    "\n",
    "            clean_text = clean_text.strip()\n",
    "            row_text.append(clean_text)\n",
    "            \n",
    "            #############################\n",
    "            # Add to your counter\n",
    "            cell_counter += 1\n",
    "\n",
    "        if '|' in row_text[0]:\n",
    "            cell_1 = row_text[0]\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            if 'cell_1' not in dir():\n",
    "                cell_1 = 'nothing'\n",
    "            row_text.insert(0, cell_1)\n",
    "\n",
    "        if len(row_text) >r_n:\n",
    "            # removes first item, we don't want it...\n",
    "            row_text.pop(0)\n",
    "\n",
    "        if len(row_text) <r_n:\n",
    "            x = row_text[-1]\n",
    "            # How many items are you missing? (diff)\n",
    "            diff = r_n - len(row_text)\n",
    "            for i in range(diff):\n",
    "                # for each item missing, append\n",
    "                row_text.append(x)\n",
    "\n",
    "        # Add the link to the row text\n",
    "        row_text.append(link)\n",
    "        \n",
    "        parsed_table_data.append(row_text)\n",
    "    \n",
    "    ## ONTO PART II\n",
    "    headers = parsed_table_data.pop(0)\n",
    "    headers[-1] = 'Url'\n",
    "    df = pd.DataFrame(parsed_table_data, columns=headers)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Get Musicals\n",
    "Scrape that wikipedia stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T01:02:36.808191Z",
     "start_time": "2019-01-24T01:02:36.803964Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Tony_Award_for_Best_Musical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T01:02:37.595225Z",
     "start_time": "2019-01-24T01:02:37.366305Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tables = get_tables_from_url(url)\n",
    "df=pd.DataFrame()\n",
    "for table in tables:\n",
    "    sub_df = get_df_from_table(table)\n",
    "    df = df.append(sub_df,ignore_index=True)\n",
    "    \n",
    "name_root = url.split('/')[-1]\n",
    "df_name = 'Wikipedia_scrape_' + name_root + '.csv'\n",
    "df.to_csv(df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Get Plays\n",
    "Scrape that wikipedia stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T01:02:46.562288Z",
     "start_time": "2019-01-24T01:02:46.555807Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Tony_Award_for_Best_Play'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T01:02:47.436824Z",
     "start_time": "2019-01-24T01:02:47.172527Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tables = get_tables_from_url(url)\n",
    "df=pd.DataFrame()\n",
    "for table in tables:\n",
    "    sub_df = get_df_from_table(table)\n",
    "    df = df.append(sub_df,ignore_index=True)\n",
    "    \n",
    "name_root = url.split('/')[-1]\n",
    "df_name = 'Wikipedia_scrape_' + name_root + '.csv'\n",
    "df.to_csv(df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Get Revival of a Musical\n",
    "Scrape that wikipedia stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T01:02:56.266121Z",
     "start_time": "2019-01-24T01:02:56.263161Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Tony_Award_for_Best_Revival_of_a_Musical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T01:02:56.629451Z",
     "start_time": "2019-01-24T01:02:56.447385Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tables = get_tables_from_url(url)\n",
    "df=pd.DataFrame()\n",
    "for table in tables:\n",
    "    sub_df = get_df_from_table(table)\n",
    "    df = df.append(sub_df,ignore_index=True)\n",
    "    \n",
    "name_root = url.split('/')[-1]\n",
    "df_name = 'Wikipedia_scrape_' + name_root + '.csv'\n",
    "df.to_csv(df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Get Revival of Plays\n",
    "Scrape that wikipedia stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T01:02:56.800929Z",
     "start_time": "2019-01-24T01:02:56.797426Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Tony_Award_for_Best_Revival_of_a_Play'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T01:02:57.874635Z",
     "start_time": "2019-01-24T01:02:56.945817Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tables = get_tables_from_url(url)\n",
    "df=pd.DataFrame()\n",
    "for table in tables:\n",
    "    sub_df = get_df_from_table(table)\n",
    "    df = df.append(sub_df,ignore_index=True)\n",
    "    \n",
    "name_root = url.split('/')[-1]\n",
    "df_name = 'Wikipedia_scrape_' + name_root + '.csv'\n",
    "df.to_csv(df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Finished!\n",
    "Done! Each is in its own df.\n",
    "\n",
    "<hr>\n",
    "<i>\n",
    "    Maybe make a single df with a column representing the category of a tony nominee? Also, would be nice to include which ones are winners. This can be done in the next iteration.  \n",
    "    </i>\n",
    "    <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Load df\n",
    "<i>\n",
    "If you want to load the files you just downloaded... \n",
    "</i>\n",
    "<pre>\n",
    "get_files(dir_in = os.getcwd(), csv_in = True):\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T01:02:57.883879Z",
     "start_time": "2019-01-24T01:02:57.878109Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_files(dir_in = os.getcwd(), csv_in = True):\n",
    "    \"\"\"\n",
    "    returns a list of paths of files\n",
    "    option to include csvs\n",
    "    requires you load os\n",
    "    \"\"\"\n",
    "    files = [x for x in os.listdir(dir_in)]\n",
    "    file_paths = [os.path.abspath(x) for x in os.listdir(dir_in)]\n",
    "    csv_paths = [x for x in file_paths if x.endswith('.csv')]\n",
    "    \n",
    "    if csv_in is False:\n",
    "        return file_paths\n",
    "    else:\n",
    "        return csv_paths\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T01:03:34.957467Z",
     "start_time": "2019-01-24T01:03:34.935552Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file is here!\n",
      "                     Year         Musical  \\\n",
      "0  1949 | 3rd Tony Awards   Kiss Me, Kate   \n",
      "1  1950 | 4th Tony Awards   South Pacific   \n",
      "2  1951 | 5th Tony Awards  Guys and Dolls   \n",
      "3  1952 | 6th Tony Awards  The King and I   \n",
      "4  1953 | 7th Tony Awards  Wonderful Town   \n",
      "\n",
      "                                  Book              Music  \\\n",
      "0               Bella & Samuel Spewack        Cole Porter   \n",
      "1  Oscar Hammerstein II & Joshua Logan    Richard Rodgers   \n",
      "2            Abe Burrows & Jo Swerling      Frank Loesser   \n",
      "3                 Oscar Hammerstein II    Richard Rodgers   \n",
      "4      Jerome Chodorov & Joseph Fields  Leonard Bernstein   \n",
      "\n",
      "                        Lyrics  \\\n",
      "0                  Cole Porter   \n",
      "1                  Hammerstein   \n",
      "2                Frank Loesser   \n",
      "3                  Hammerstein   \n",
      "4  Betty Comden & Adolph Green   \n",
      "\n",
      "                                                 Url  \n",
      "0        https://en.wikipedia.org/wiki/Kiss_Me,_Kate  \n",
      "1  https://en.wikipedia.org/wiki/South_Pacific_(m...  \n",
      "2       https://en.wikipedia.org/wiki/Guys_and_Dolls  \n",
      "3       https://en.wikipedia.org/wiki/The_King_and_I  \n",
      "4       https://en.wikipedia.org/wiki/Wonderful_Town  \n",
      "the file you want isn't here\n",
      "the file you want isn't here\n",
      "the file you want isn't here\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csvs = get_files()\n",
    "for x in csvs:\n",
    "    if x.endswith('Wikipedia_scrape_Tony_Award_for_Best_Musical.csv'):\n",
    "        df = pd.read_csv(x,index_col=0)\n",
    "        print ('file is here!')\n",
    "        print(df.head(5))\n",
    "    else:\n",
    "        print ('the file you want isn\\'t here')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
