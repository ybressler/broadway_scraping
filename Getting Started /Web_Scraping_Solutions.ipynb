{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Web Scraping Solutions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ybressler/broadway_scraping/blob/master/Getting%20Started%20/Web_Scraping_Solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "_SElCgNBBv87",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\" size=6>Problem Solving with Web Scraping:</font>\n",
        "\n",
        "<br>\n",
        "**The problem is as follows:**\n",
        "<br>\n",
        "  \n",
        ">***I am trying to get all the H2 titles from a website.*** *It works when I scrape one page. But I'm trying to use a for loop to go thru each page, get the titles and add it to a list, its giving me ...*\n",
        "\n",
        ">>`AttributeError: ResultSet object has no attribute 'find_all'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?`\n",
        "\n",
        "\n",
        "\n",
        ">***CODE BELOW:***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "    import requests\n",
        "    from bs4 import BeautifulSoup as soup\n",
        "\n",
        "    title_list = []\n",
        "    url = 'http://www.spoon-tamago.com/page/'\n",
        "\n",
        "    for i in range(229):\n",
        "        url = url + str(i)\n",
        "        r = requests.get(url)\n",
        "        soup = soup(r.text, 'html')\n",
        "        temp = soup.find_all({'h2' : {'class' : 'post-title'}})\n",
        "        for x in temp:\n",
        "            title = x.getText()\n",
        "            title_list.append(title)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "\n",
        "<font color=\"blue\" size=6>Solution:</font><br>\n",
        " <font color=\"blue\" size=4> The re-use of the variable `url` as well as the variable name `soup` which is also a function is interfering with the code. Straightening those out seems to have fixed the code.\n",
        "\n",
        "  \n",
        "</font>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>"
      ]
    },
    {
      "metadata": {
        "id": "6c-LVNAUBndz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup as soup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ilrvz6WNBqB7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "title_list = []\n",
        "url = 'http://www.spoon-tamago.com/page/'\n",
        "\n",
        "\n",
        "for i in range(229):\n",
        "  new_url = url + str(i)\n",
        "  r = requests.get(new_url)\n",
        "  text_soup = soup(r.text, 'html')\n",
        "  temp = text_soup.find_all({'h2' : {'class' : 'post-title'}})\n",
        "  \n",
        "  if i%29 ==0:\n",
        "    print(i)\n",
        "  for x in temp:\n",
        "    title = x.getText()\n",
        "    title_list.append(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "moS16RUbEe0n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f83bd9bb-6322-4851-a6a4-1d595611a01a"
      },
      "cell_type": "code",
      "source": [
        "print('You\\'ve scraped {} titles from this website!'.format(len(title_list)))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You've scraped 2407 titles from this website!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}